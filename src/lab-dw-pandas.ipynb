{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae7c66-9458-477c-8a31-c6b07a36bf66",
   "metadata": {},
   "source": [
    "Objective: practice how to use the pandas library in Python for data analysis and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/ironhack-labs/lab-customer-analysis-round-1/master/files_for_lab/csv_files/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0f9a6-d7cf-4f95-9f7d-e58d2a0f0a23",
   "metadata": {},
   "source": [
    "- To ensure consistency and ease of use, standardize the column names of the dataframe. Start by taking a first look at the dataframe and identifying any column names that need to be modified. Use appropriate naming conventions and make sure that column names are descriptive and informative.\n",
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types.\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics.\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics.\n",
    "- The Gender and Customer Lifetime Value columns in the dataset appear to have incorrect values or incorrect data type. In order to analyze the data accurately, we need to correct these columns. Please update the columns to ensure that it only contains valid data. Note that we will not deal with null values (NaN or None) in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e8cd8-a6f6-486c-a5c4-1745b0c035f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a703890-63db-4944-b7ab-95a4f8185120",
   "metadata": {},
   "source": [
    "## Challenge 2: analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca5073-4520-4f42-9390-4b92733284ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc33e9-20fa-4852-8a96-acba1c802dd3",
   "metadata": {},
   "source": [
    "### Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340432f9-b380-4861-84ec-bc6b59b6b673",
   "metadata": {},
   "source": [
    "You have been tasked with analyzing the data to identify potential areas for improving customer retention and profitability. Your goal is to identify customers with a high policy claim amount and a low customer lifetime value.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount and customer lifetime value to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount and a low customer lifetime value. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount, and clients with a low customer lifetime value to be those in the bottom 25% of the customer lifetime value. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile and a customer lifetime value in the bottom 25th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount and low customer lifetime value data. To do so, select both columns of the dataframe simultaneously and pass it to the .describe() method. This will give you descriptive statistics, such as mean, median, standard deviation, minimum and maximum values for both columns at the same time, allowing you to compare and analyze their characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f294e-f425-41b5-b5ff-398d955d346f",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731bca6-a760-4860-a27b-a33efa712ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d37304-293f-416a-ae6f-1ce25a0481e8",
   "metadata": {},
   "source": [
    "The output of this code will be a DataFrame object containing summary statistics about the high policy claim amount and low customer lifetime value data. You can then use this data to create a report summarizing the findings. For example, you could write a report that highlights the fact that a significant number of customers are making large claims but have a low customer lifetime value, which could indicate that they are not loyal customers and may not be profitable for the company in the long term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82652369-bba8-447c-9ef2-eda16c671452",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd770f57-0061-4b2c-b3ed-b448c9772feb",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfad6c1-9af2-4b0b-9aa9-0dc5c17473c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5312b2-77a2-4f9a-a050-dadf54dfb0f7",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a higher total claim amount than those with Corporate Auto. How does the average total claim amount compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579590ea-2e79-4027-91b7-06fda83b22dc",
   "metadata": {},
   "source": [
    "- Use loc to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average Customer Lifetime Value for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0563cf-6f8b-463d-a321-651a972f82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
